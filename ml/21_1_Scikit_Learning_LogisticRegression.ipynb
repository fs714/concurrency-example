{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample Generation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "\n",
    "# X为样本特征，y为样本簇类别，共1000个样本，每个样本2个特征，共2个簇\n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[0.3, 0.4],\n",
    "                          random_state=9)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['r', 'b']\n",
    "for y, c in zip(np.unique(y_all), colors):\n",
    "    plt.scatter(X_all[y_all==y, 0], x_all[y_all==y, 1], c=c, label=y, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain decision_function, predict_proba and predict\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid_array(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[1, 1],\n",
    "                          random_state=9)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(C=1, intercept_scaling=1, random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.classes_)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.n_iter_)\n",
    "print(clf.densify())\n",
    "print(clf.get_params(deep=True))\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "y_confidence = clf.decision_function(x_test)\n",
    "y_sigmoid = sigmoid_array(y_confidence)\n",
    "\n",
    "result = pd.DataFrame({'y': y_test,\n",
    "                       'y_pred': y_pred,\n",
    "                       'y_pred_proba': y_pred_proba[:, 1],\n",
    "                       'y_confidence': y_confidence,\n",
    "                       'y_sigmoid': y_sigmoid})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explain how to calculate decision_function\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid_array(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[1, 1],\n",
    "                          random_state=9)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(C=1, intercept_scaling=1, random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.classes_)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "\n",
    "def func(x):\n",
    "    return x[0] * clf.coef_[0][0] + x[1] * clf.coef_[0][1] + clf.intercept_\n",
    "\n",
    "y_calc = np.apply_along_axis(func, axis=1, arr=x_test)\n",
    "y_confidence = clf.decision_function(x_test)\n",
    "\n",
    "result = pd.DataFrame({'y_calc': y_calc[:, 0], 'y_confidence': y_confidence})\n",
    "print(result)\n",
    "\n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example for intercept_scaling in LogisticRegression\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[2, 2],\n",
    "                          random_state=9)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, random_state=1)\n",
    "\n",
    "\n",
    "sc_list = np.linspace(0.1, 1, 10)\n",
    "for sc in sc_list:\n",
    "    print('intercept_scaling = {}'.format(sc))\n",
    "    clf = LogisticRegression(C=1, intercept_scaling=sc, random_state=1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # print(classification_report(y_train, clf.predict(x_train)))\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example for Prediction Threshold\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[2, 2],\n",
    "                          random_state=9)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(C=1, intercept_scaling=1, random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(classification_report(y_train, clf.predict(x_train)))\n",
    "print(classification_report(y_test, clf.predict(x_test)))\n",
    "\n",
    "pred_proba_train = clf.predict_proba(x_train)[:, 1]\n",
    "pred_proba_test = clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_train, (pred_proba_train > 0.6)))\n",
    "print(classification_report(y_test, (pred_proba_test > 0.6)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "x_all, y_all = make_blobs(n_samples=1000, n_features=2, \n",
    "                          centers=[[5,5], [6,6]],\n",
    "                          cluster_std=[2, 2],\n",
    "                          random_state=9)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "tuned_parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                     'intercept_scaling': [0.1, 0.5, 1, 5, 10]}]\n",
    "\n",
    "# Tuning hyper-parameters\n",
    "clf = GridSearchCV(LogisticRegression(),tuned_parameters, cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best score found on test set:\")\n",
    "print(clf.best_score_)\n",
    "print()\n",
    "\n",
    "print(\"Best score found on test set:\")\n",
    "print(clf.best_estimator_)\n",
    "print()\n",
    "\n",
    "print(\"Best parameters set found on test set:\")\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_.get_params())\n",
    "print()\n",
    "\n",
    "print(\"Grid scores on test set:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, std, params in zip(means, stds, params):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "y_true, y_pred = y_test, clf.predict(x_test)\n",
    "print('Score of best_estimator_: {}'.format(clf.score(x_test, y_test)))\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
